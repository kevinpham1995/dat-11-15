{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Lab w/ Keras + Deep Learning\n",
    "\n",
    "Welcome to tonight's lab!  For today we're going to try and re-build what was covered in the previous class, but with you behind the driver's wheel.  \n",
    "\n",
    "The purpose is to allow ourselves to better understand the details of model building with neural networks by forcing yourself to recreate what was already covered.  Everything gets more clear with practice.\n",
    "\n",
    "You can refer to class notes from the previous lab, but it's best to try and force yourself to try and remember what you're supposed to do from memory first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import the necessary modules:  numpy, pandas, tensorflow and keras, and load in the dataset.  You can find it in the `data` folder in the `Unit4` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Data Cleaning.  \n",
    "\n",
    "Now go ahead and do some necessary data prep for our modeling.  Try and take the following steps:\n",
    "\n",
    " - Convert the `sentiment` column to 1 and 0\n",
    " - Remove `<br>` tags\n",
    " - Create training and test sets with an 80 / 20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Language Processing\n",
    "\n",
    "We'll now go ahead and convert our word corpus into numeric form that can be used for modeling.  We'll do so with the following steps:\n",
    "\n",
    " - Create a tokenizer with a vocabulary size of 10,000 words\n",
    " - Use it to transform the training and test sets (make sure to transform the training set using values in the test set)\n",
    " - Arrange your samples so that all of them are 300 characters long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Knowledge check:** Can you make sense out of why your new values for `X_train` and `X_test` appear the way they do?  \n",
    "  - Why are there 0's?\n",
    "  - Can you take your numbers and reverse-engineer them back into their original words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Construct a sequential model\n",
    "\n",
    "Now use the `Sequential` module in keras to build a network with the following layers:\n",
    "\n",
    "- A word embedding with 64 weights for each word in our corpus\n",
    "- A layer to resize the embedding output back into two dimensions\n",
    "- Two dense layers with 64 columns of weights each\n",
    "- A dense layer at the end for the final prediction\n",
    "\n",
    "**Note:** Use the appropriate activation functions where necessary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Knowledge check:**  Can you describe what your activation functions actually do?  Specifically:\n",
    " - Could you write a function in regular python that would recreate their behavior?\n",
    " - Can you explain why each one is useful for where it's being used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Compile your model. \n",
    "\n",
    "This part is a little bit different from what we've done previously.  For a neural network, you have to explicitly tell it what type of loss function to use and (optionally) what metrics to track during training.  \n",
    "\n",
    "Take a moment and read through the keras documentation to find the one that best suits this purpose:  https://keras.io/api/losses/ and use it in the compilation step.  \n",
    "\n",
    "Also specify that your model use the accuracy metric during training.  You can read more about available metrics here:  https://keras.io/api/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Fit your model.\n",
    "\n",
    "Use the following criteria:\n",
    "\n",
    " - 5 epochs (fitting rounds)\n",
    " - Use 20% of your training data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7:** Make a prediction with your model on a single training sample to validate that it works, and evaluate your test set, and compare with your maximum validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
